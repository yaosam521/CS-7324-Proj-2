{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37908c56-ae0f-45c9-b019-bc3864fd3e0d",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "by:\n",
    "- Rebecca Kuhlman\n",
    "- Michael Amberg\n",
    "- Sam Yao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45028-38cc-4d4b-89f0-8c6bc361356b",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "Identifying the type of brain tumor a patient has is an important step in figuring out the treatment plan of a patient. They can be diagnosed via MRI imaging, leading to interest in using machine learning to diagnose the patient. Having a second opinion on brain tumor diagnoses would help improve patient care and outcomes, and lessen stress on doctors. A machine learning model could also speed up analysis time and pick out which patients are in need of urgent treatment.\n",
    "\n",
    "In this dataset, there is glioma, meningioma, and pituitary tumors, as well as MRI images with no tumors.\n",
    "Glioma tumors are usually malignant, while meningioma and pituitary tumors are usually benign. Different types of tumors are made of different types of cells and have a location where they are most likely to be located.\n",
    "More information can be found at: https://www.mayoclinic.org/diseases-conditions/brain-tumor/symptoms-causes/syc-20350084\n",
    "\n",
    "There are many other types of tumors that future algorithms will be need to address. The majority of other types of tumors are more common in children, while the set we are dealing with are all adult brain images.\n",
    "\n",
    "Because the model deals with health conditions that have extreme affects on the patient, model accuracy is extremely important. Furthermore, accuracy must fine-tuned to avoid fatal misdiagnosis. While incorrectly marking a patient with a benign tumor as malignant is wasteful, the adverse affects are minimal. Inversely, misdiagnosing a malignant tumor as benign may have fatal effects for the patient. Therefore, the designed model must minimize the rate of false negatives with accuracy of 95% or more.\n",
    "\n",
    "It should be noted that the majority of misdiagnose of brain tumors happen before a brain scan or related test is ordered.\n",
    "https://paulandperkins.com/brain-tumors/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617b08d-342f-4b9f-bed7-7de11cbbcd11",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e608d-78c3-49eb-aa11-90f6ace85011",
   "metadata": {},
   "source": [
    "Several helpful sources that helped this part of the section include:\n",
    "- [1] https://pillow.readthedocs.io/en/stable/handbook/tutorial.html\n",
    "- [2] https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a198ffb6-8712-4419-94d6-92a570e85347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image # Utilized Source [2]\n",
    "\n",
    "'''img = Image.open(\"./Training/glioma_tumor/gg (1).jpg\") # Utilized Source [1]\n",
    "img_arr = np.array(img)\n",
    "new_arr = list()\n",
    "for x in img_arr:\n",
    "    for y in x:\n",
    "        new_arr.append(y)\n",
    "print(len(new_arr))'''\n",
    "# This method creates the data, whether training or testing, in the form we desire\n",
    "# Uses code from source [2] to create the training datasets\n",
    "def create_dataset(img_folder):\n",
    "    # Read through all files in \"./Training\"\n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= np.array(Image.open(image_path).convert(\"L\"))\n",
    "\n",
    "            image = image.flatten() #Vectorizes each image\n",
    "            \n",
    "            image = image.astype('float32')\n",
    "            image /= 255  \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    # return array with training data.\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092cc69c-f409-4eb0-9034-72751c377ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, training_classes = create_dataset(\"./Training\")\n",
    "#df_testing, testing_classes = create_dataset(\"./Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f7e97c-0842-4b60-97ba-74a0ad069a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(262144,)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c42807",
   "metadata": {},
   "source": [
    "## Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78788575",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bea66a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.8 GiB for an array with shape (1876, 1988250) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# get some of the specifics of the dataset\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#dfTrain = pd.DataFrame.from_records(df_training)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m dfTrain \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_training\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(dfTrain)\n\u001B[0;32m      5\u001B[0m X \u001B[38;5;241m=\u001B[39m dfTrain\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:746\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    745\u001B[0m         columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[1;32m--> 746\u001B[0m     arrays, columns, index \u001B[38;5;241m=\u001B[39m \u001B[43mnested_data_to_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[0;32m    748\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[0;32m    749\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    752\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    754\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[0;32m    755\u001B[0m         arrays,\n\u001B[0;32m    756\u001B[0m         columns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    759\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    760\u001B[0m     )\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:510\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[1;34m(data, columns, index, dtype)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_named_tuple(data[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    508\u001B[0m     columns \u001B[38;5;241m=\u001B[39m ensure_index(data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fields)\n\u001B[1;32m--> 510\u001B[0m arrays, columns \u001B[38;5;241m=\u001B[39m \u001B[43mto_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    511\u001B[0m columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:873\u001B[0m, in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, dtype)\u001B[0m\n\u001B[0;32m    870\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;66;03m# last ditch effort\u001B[39;00m\n\u001B[0;32m    872\u001B[0m     data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtuple\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[1;32m--> 873\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43m_list_to_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    875\u001B[0m content, columns \u001B[38;5;241m=\u001B[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content, columns\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:883\u001B[0m, in \u001B[0;36m_list_to_arrays\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_list_to_arrays\u001B[39m(data: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;66;03m# Returned np.ndarray has ndim = 2\u001B[39;00m\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;66;03m# Note: we already check len(data) > 0 before getting hre\u001B[39;00m\n\u001B[0;32m    882\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 883\u001B[0m         content \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_object_array_tuples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    885\u001B[0m         \u001B[38;5;66;03m# list of lists\u001B[39;00m\n\u001B[0;32m    886\u001B[0m         content \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mto_object_array(data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:3029\u001B[0m, in \u001B[0;36mpandas._libs.lib.to_object_array_tuples\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 27.8 GiB for an array with shape (1876, 1988250) and data type object"
     ]
    }
   ],
   "source": [
    "# get some of the specifics of the dataset\n",
    "#dfTrain = pd.DataFrame.from_records(df_training)\n",
    "dfTrain = pd.DataFrame(data=df_training, columns=training_classes)\n",
    "print(dfTrain)\n",
    "X = dfTrain.data\n",
    "y = training_classes\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "_, h, w = img_arr.shape\n",
    "n_classes = 4\n",
    "\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_classes: {}\".format(n_classes))\n",
    "print(\"Original Image Sizes {} by {}\".format(h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lets do some PCA of the features and go from 1850 features to 20 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, h))\n",
    "\n",
    "pca = PCA(n_components= n_components)\n",
    "pca.fit(X.copy())\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524dd1c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(trans_obj,org_features):\n",
    "    low_rep = trans_obj.transform(org_features)\n",
    "    rec_image = trans_obj.inverse_transform(low_rep)\n",
    "    return low_rep, rec_image\n",
    "\n",
    "idx_to_reconstruct = 1\n",
    "X_idx = X[idx_to_reconstruct]\n",
    "low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X_idx.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7791a1",
   "metadata": {},
   "source": [
    " randomized principle components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1b3e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, X.shape[0]))\n",
    "\n",
    "rpca = PCA(n_components=n_components, svd_solver='randomized')\n",
    "%time rpca.fit(X.copy())\n",
    "eigenfaces = rpca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e9204",
   "metadata": {},
   "source": [
    "Compare the representation using PCA and Randomized PCA. The method you choose to compare dimensionality methods should quantitatively explain which method is better at representing the images with fewer components.  Do you prefer one method over another? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc100fd-a872-4c07-a457-b645624831e7",
   "metadata": {},
   "source": [
    "feature extraction upon the images using DAISY. Try different parameters for your image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f380f8-8286-4240-a944-d24b84df2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import daisy\n",
    "\n",
    "# lets first visualize what the daisy descriptor looks like\n",
    "features, img_desc = daisy(img,\n",
    "                           step=20,\n",
    "                           radius=20,\n",
    "                           rings=2,\n",
    "                           histograms=8,\n",
    "                           orientations=8,\n",
    "                           visualize=True)\n",
    "imshow(img_desc)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a0f33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# now let's understand how to use it\n",
    "features = daisy(img, step=20, radius=20, rings=2, histograms=8, orientations=4, visualize=False)\n",
    "print(features.shape)\n",
    "print(features.shape[0]*features.shape[1]*features.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16aedc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a function to take in the row of the matrix and return a new feature\n",
    "def apply_daisy(row,shape):\n",
    "    feat = daisy(row.reshape(shape), step=20, radius=20,\n",
    "                 rings=2, histograms=8, orientations=4,\n",
    "                 visualize=False)\n",
    "    return feat.reshape((-1))\n",
    "\n",
    "%time test_feature = apply_daisy(X[3],(h,w))\n",
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab11ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# find closest image to current image\n",
    "idx1 = 5\n",
    "distances = copy.deepcopy(dist_matrix[idx1,:])\n",
    "distances[idx1] = np.infty # dont pick the same image!\n",
    "idx2 = np.argmin(distances)\n",
    "\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(1,2,1)\n",
    "imshow(X[idx1].reshape((h,w)))\n",
    "plt.title(\"Original Image\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "imshow(X[idx2].reshape((h,w)))\n",
    "plt.title(\"Closest Image\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a310781",
   "metadata": {},
   "source": [
    "Does this feature extraction method show promise for your prediction task? Why?\n",
    "Use visualizations to analyze this questions. For example, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d288f5-6294-4ffc-b5e1-b7b2f4bd6179",
   "metadata": {},
   "source": [
    "## Exceptional Work ðŸ˜¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868752fd",
   "metadata": {},
   "source": [
    "Additional feature extraction techniques(Gabor filters, keypoint matching, ordered gradients) Several are provided in the notebooks and you might research techniques known in the computer vision literature.\n",
    "Does this feature extraction method show promise for your prediction task? Why?\n",
    "Use visualizations to analyze this questions. For example, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb467a8-0d45-4b50-9ecf-cc023520f0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
