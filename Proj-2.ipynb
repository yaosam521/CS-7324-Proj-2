{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37908c56-ae0f-45c9-b019-bc3864fd3e0d",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "by:\n",
    "- Rebecca Kuhlman\n",
    "- Michael Amberg\n",
    "- Sam Yao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45028-38cc-4d4b-89f0-8c6bc361356b",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "Identifying the type of brain tumor a patient has is an important step in figuring out the treatment plan of a patient. They can be diagnosed via MRI imaging, leading to interest in using machine learning to diagnose the patient. Having a second opinion on brain tumor diagnoses would help improve patient care and outcomes, and lessen stress on doctors. A machine learning model could also speed up analysis time and pick out which patients are in need of urgent treatment.\n",
    "\n",
    "In this dataset, there is glioma, meningioma, and pituitary tumors, as well as MRI images with no tumors.\n",
    "Glioma tumors are usually malignant, while meningioma and pituitary tumors are usually benign. Different types of tumors are made of different types of cells and have a location where they are most likely to be located.\n",
    "More information can be found at: https://www.mayoclinic.org/diseases-conditions/brain-tumor/symptoms-causes/syc-20350084\n",
    "\n",
    "There are many other types of tumors that future algorithms will be need to address. The majority of other types of tumors are more common in children, while the set we are dealing with are all adult brain images.\n",
    "\n",
    "Because the model deals with health conditions that have extreme affects on the patient, model accuracy is extremely important. Furthermore, accuracy must fine-tuned to avoid fatal misdiagnosis. While incorrectly marking a patient with a benign tumor as malignant is wasteful, the adverse affects are minimal. Inversely, misdiagnosing a malignant tumor as benign may have fatal effects for the patient. Therefore, the designed model must minimize the rate of false negatives with accuracy of 95% or more.\n",
    "\n",
    "It should be noted that the majority of misdiagnose of brain tumors happen before a brain scan or related test is ordered.\n",
    "https://paulandperkins.com/brain-tumors/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617b08d-342f-4b9f-bed7-7de11cbbcd11",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e608d-78c3-49eb-aa11-90f6ace85011",
   "metadata": {},
   "source": [
    "Several helpful sources that helped this part of the section include:\n",
    "- [1] https://pillow.readthedocs.io/en/stable/handbook/tutorial.html\n",
    "- [2] https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a198ffb6-8712-4419-94d6-92a570e85347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image # Utilized Source [2]\n",
    "\n",
    "'''img = Image.open(\"./Training/glioma_tumor/gg (1).jpg\") # Utilized Source [1]\n",
    "img_arr = np.array(img)\n",
    "new_arr = list()\n",
    "for x in img_arr:\n",
    "    for y in x:\n",
    "        new_arr.append(y)\n",
    "print(len(new_arr))'''\n",
    "# This method creates the data, whether training or testing, in the form we desire\n",
    "# Uses code from source [2] to create the training datasets\n",
    "def create_dataset(img_folder):\n",
    "    # Read through all files in \"./Training\"\n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= np.array(Image.open(image_path).convert(\"L\"))\n",
    "\n",
    "            image = image.flatten() #Vectorizes each image\n",
    "            \n",
    "            image = image.astype('float32')\n",
    "            image /= 255  \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    # return array with training data.\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cc69c-f409-4eb0-9034-72751c377ad5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_training, training_classes = create_dataset(\"./Training\")\n",
    "df_testing, testing_classes = create_dataset(\"./Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1f7e97c-0842-4b60-97ba-74a0ad069a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57348,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c42807",
   "metadata": {},
   "source": [
    "## Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78788575",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bea66a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get some of the specifics of the dataset\n",
    "#dfTrain = pd.DataFrame.from_records(df_training)\n",
    "dfTrain = pd.DataFrame(data=df_training, columns=training_classes)\n",
    "print(dfTrain)\n",
    "X = dfTrain.data\n",
    "y = training_classes\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "_, h, w = img_arr.shape\n",
    "n_classes = 4\n",
    "\n",
    "print(\"n_samples: {}\".format(n_samples))\n",
    "print(\"n_classes: {}\".format(n_classes))\n",
    "print(\"Original Image Sizes {} by {}\".format(h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 300 eigenfaces from 512 faces\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;31mTypeError\u001B[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting the top \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m eigenfaces from \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m faces\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[0;32m      6\u001B[0m     n_components, h))\n\u001B[0;32m      8\u001B[0m pca \u001B[38;5;241m=\u001B[39m PCA(n_components\u001B[38;5;241m=\u001B[39m n_components)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mpca\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m eigenfaces \u001B[38;5;241m=\u001B[39m pca\u001B[38;5;241m.\u001B[39mcomponents_\u001B[38;5;241m.\u001B[39mreshape((n_components, h, w))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:435\u001B[0m, in \u001B[0;36mPCA.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model with X.\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \n\u001B[0;32m    419\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;124;03m    Returns the instance itself.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 435\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001B[0m, in \u001B[0;36mPCA._fit\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPCA does not support sparse input. See \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTruncatedSVD for a possible alternative.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    483\u001B[0m     )\n\u001B[1;32m--> 485\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;66;03m# Handle n_components==None\u001B[39;00m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:546\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 546\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    547\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    877\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    878\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 879\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    882\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    883\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    182\u001B[0m     xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(array)\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xp\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy.array_api\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;66;03m# Use NumPy API to support order\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001B[0m, in \u001B[0;36mNDFrame.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   2069\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: npt\u001B[38;5;241m.\u001B[39mDTypeLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m-> 2070\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# lets do some PCA of the features and go from 1850 features to 20 features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 300\n",
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, h))\n",
    "\n",
    "pca = PCA(n_components= n_components)\n",
    "pca.fit(X.copy())\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524dd1c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(trans_obj,org_features):\n",
    "    low_rep = trans_obj.transform(org_features)\n",
    "    rec_image = trans_obj.inverse_transform(low_rep)\n",
    "    return low_rep, rec_image\n",
    "\n",
    "idx_to_reconstruct = 1\n",
    "X_idx = X[idx_to_reconstruct]\n",
    "low_dimensional_representation, reconstructed_image = reconstruct_image(pca,X_idx.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7791a1",
   "metadata": {},
   "source": [
    " randomized principle components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1b3e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Extracting the top %d eigenfaces from %d faces\" % (\n",
    "    n_components, X.shape[0]))\n",
    "\n",
    "rpca = PCA(n_components=n_components, svd_solver='randomized')\n",
    "%time rpca.fit(X.copy())\n",
    "eigenfaces = rpca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e9204",
   "metadata": {},
   "source": [
    "Compare the representation using PCA and Randomized PCA. The method you choose to compare dimensionality methods should quantitatively explain which method is better at representing the images with fewer components.  Do you prefer one method over another? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc100fd-a872-4c07-a457-b645624831e7",
   "metadata": {},
   "source": [
    "feature extraction upon the images using DAISY. Try different parameters for your image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f380f8-8286-4240-a944-d24b84df2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import daisy\n",
    "\n",
    "# lets first visualize what the daisy descriptor looks like\n",
    "features, img_desc = daisy(img,\n",
    "                           step=20,\n",
    "                           radius=20,\n",
    "                           rings=2,\n",
    "                           histograms=8,\n",
    "                           orientations=8,\n",
    "                           visualize=True)\n",
    "imshow(img_desc)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a0f33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# now let's understand how to use it\n",
    "features = daisy(img, step=20, radius=20, rings=2, histograms=8, orientations=4, visualize=False)\n",
    "print(features.shape)\n",
    "print(features.shape[0]*features.shape[1]*features.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16aedc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create a function to take in the row of the matrix and return a new feature\n",
    "def apply_daisy(row,shape):\n",
    "    feat = daisy(row.reshape(shape), step=20, radius=20,\n",
    "                 rings=2, histograms=8, orientations=4,\n",
    "                 visualize=False)\n",
    "    return feat.reshape((-1))\n",
    "\n",
    "%time test_feature = apply_daisy(X[3],(h,w))\n",
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab11ac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# find closest image to current image\n",
    "idx1 = 5\n",
    "distances = copy.deepcopy(dist_matrix[idx1,:])\n",
    "distances[idx1] = np.infty # dont pick the same image!\n",
    "idx2 = np.argmin(distances)\n",
    "\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(1,2,1)\n",
    "imshow(X[idx1].reshape((h,w)))\n",
    "plt.title(\"Original Image\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "imshow(X[idx2].reshape((h,w)))\n",
    "plt.title(\"Closest Image\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a310781",
   "metadata": {},
   "source": [
    "Does this feature extraction method show promise for your prediction task? Why?\n",
    "Use visualizations to analyze this questions. For example, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d288f5-6294-4ffc-b5e1-b7b2f4bd6179",
   "metadata": {},
   "source": [
    "## Exceptional Work ðŸ˜¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868752fd",
   "metadata": {},
   "source": [
    "Additional feature extraction techniques(Gabor filters, keypoint matching, ordered gradients) Several are provided in the notebooks and you might research techniques known in the computer vision literature.\n",
    "Does this feature extraction method show promise for your prediction task? Why?\n",
    "Use visualizations to analyze this questions. For example, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb467a8-0d45-4b50-9ecf-cc023520f0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
